// This file was generated by gpufort

#include "hip/hip_complex.h"
#include "hip/hip_runtime.h"
#include "hip/math_functions.h"
#include <algorithm>
#include <cstdio>
#include <iostream>

#define HIP_CHECK(condition)                                                                                                               \
  {                                                                                                                                        \
    hipError_t error = condition;                                                                                                          \
    if (error != hipSuccess) {                                                                                                             \
      std::cout << "HIP error: " << error << " line: " << __LINE__ << std::endl;                                                           \
      exit(error);                                                                                                                         \
    }                                                                                                                                      \
  }

// global thread indices for various dimensions
#define __gidx(idx) (threadIdx.idx + blockIdx.idx * blockDim.idx)
#define __gidx1 __gidx(x)
#define __gidx2 (__gidx(x) + gridDim.x * blockDim.x * __gidx(y))
#define __gidx3 (__gidx(x) + gridDim.x * blockDim.x * __gidx(y) + gridDim.x * blockDim.x * gridDim.y * blockDim.y * __gidx(z))
#define __total_threads(grid, block) ((grid).x * (grid).y * (grid).z * (block).x * (block).y * (block).z)

namespace {
template <typename I, typename E, typename S> __device__ __forceinline__ bool loop_cond(I idx, E end, S stride) {
  return (stride > 0) ? (idx <= end) : (-idx <= -end);
}

// make float
__device__ __forceinline__ float make_float(const short int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const unsigned short int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const unsigned int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const long int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const unsigned long int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const long long int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const unsigned long long int &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const signed char &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const unsigned char &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const float &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const double &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const long double &a) { return static_cast<float>(a); }
__device__ __forceinline__ float make_float(const hipFloatComplex &a) { return static_cast<float>(a.x); }
__device__ __forceinline__ float make_float(const hipDoubleComplex &a) { return static_cast<float>(a.x); }
// make double
__device__ __forceinline__ double make_double(const short int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const unsigned short int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const unsigned int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const long int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const unsigned long int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const long long int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const unsigned long long int &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const signed char &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const unsigned char &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const float &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const double &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const long double &a) { return static_cast<double>(a); }
__device__ __forceinline__ double make_double(const hipFloatComplex &a) { return static_cast<double>(a.x); }
__device__ __forceinline__ double make_double(const hipDoubleComplex &a) { return static_cast<double>(a.x); }
// conjugate complex type
__device__ __forceinline__ hipFloatComplex conj(const hipFloatComplex &c) { return hipConjf(c); }
__device__ __forceinline__ hipDoubleComplex conj(const hipDoubleComplex &z) { return hipConj(z); }

// TODO Add the following functions:
// - sign(x,y) = sign(y) * |x| - sign transfer function
// ...
} // namespace

// end of preamble
#define divideAndRoundUp(x, y) ((x) / (y) + ((x) % (y) != 0))

// BEGIN krnl_cecba2_8
/* Fortran original:
  ! parallel loop
  do i = 1, N
     x(i) = 1
     y(i) = 2
  end do

*/

__global__ void krnl_cecba2_8() {

  int i = 1 + (1) * (threadIdx.x + blockIdx.x * blockDim.x);
  if (loop_cond(i, N, 1)) {
    x[_idx_x(i)] = 1;
    y[_idx_y(i)] = 2;
  }
}

extern "C" void launch_krnl_cecba2_8(dim3 *grid, dim3 *block, const int sharedMem, hipStream_t stream, ) {

  // launch kernel
  hipLaunchKernelGGL((krnl_cecba2_8), *grid, *block, sharedMem, stream, );
}
extern "C" void launch_krnl_cecba2_8_auto(const int sharedMem, hipStream_t stream, ) {
  const unsigned int krnl_cecba2_8_blockX = -2;
  dim3 block(krnl_cecba2_8_blockX);
  const unsigned int krnl_cecba2_8_NX = (1 + ((N) - (1)));

  const unsigned int krnl_cecba2_8_gridX = -2;
  dim3 grid(krnl_cecba2_8_gridX);

  // launch kernel
  hipLaunchKernelGGL((krnl_cecba2_8), grid, block, sharedMem, stream, );
}
// END krnl_cecba2_8

// BEGIN krnl_e7eb26_15
/* Fortran original:
  ! parallel loop reduction(+:res)
  do i = 1, N
     res = res + x(i)*y(i)
  end do

*/

__global__ void krnl_e7eb26_15() {

  int i = 1 + (1) * (threadIdx.x + blockIdx.x * blockDim.x);
  if (loop_cond(i, N, 1)) {
    res = (res + x[_idx_x(i)] * y[_idx_y(i)]);
  }
}

extern "C" void launch_krnl_e7eb26_15(dim3 *grid, dim3 *block, const int sharedMem, hipStream_t stream, ) {

  // launch kernel
  hipLaunchKernelGGL((krnl_e7eb26_15), *grid, *block, sharedMem, stream, );
}
extern "C" void launch_krnl_e7eb26_15_auto(const int sharedMem, hipStream_t stream, ) {
  const unsigned int krnl_e7eb26_15_blockX = -2;
  dim3 block(krnl_e7eb26_15_blockX);
  const unsigned int krnl_e7eb26_15_NX = (1 + ((N) - (1)));

  const unsigned int krnl_e7eb26_15_gridX = -2;
  dim3 grid(krnl_e7eb26_15_gridX);

  // launch kernel
  hipLaunchKernelGGL((krnl_e7eb26_15), grid, block, sharedMem, stream, );
}
// END krnl_e7eb26_15
