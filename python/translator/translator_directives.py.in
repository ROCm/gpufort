class ILoopAnnotation():
    def numCollapse(self):
        return CLAUSE_NOT_FOUND
    def tileSizes(self):
        return [CLAUSE_NOT_FOUND]
    def numGangsTeamsBlocks(self):
        return [CLAUSE_NOT_FOUND]
    def numThreadsInBlock(self):
        return [CLAUSE_NOT_FOUND]
    def numWorkers(self): 
        """ only ACC """
        return [CLAUSE_NOT_FOUND]
    def simdlenVectorLength(self):
        return [CLAUSE_NOT_FOUND]
    def dataIndependentIterations(self):
        return True
    def privateVars(self,converter=makeFStr): 
        """ CUF,ACC: all scalars are private by default """ 
        return []
    def lastprivateVars(self,converter=makeFStr): 
        """ only OMP """
        return []
    def reductionVars(self,converter=makeFStr): 
        """ CUF: Scalar lvalues are reduced by default """
        return {}
    def sharedVars(self,converter=makeFStr): 
        """ only OMP """
        return []

class TTDoLoop(TTNode):
    def _assignFields(self,tokens):
        # Assignment, number | variable
        self._annotation, self._begin, self._end, self._step, self._body = tokens
        self._threadIndex = None # "z","y","x"
        if self._annotation is None:
            self._annotation = ILoopAnnotation()
    def annotation(self):
        return self._annotation
    def setHipThreadIndex(self,name):
        self._threadIndex = name
    def hipThreadIndexCStr(self):
        indexVar = self.loopVar()
        begin    = makeCStr(self._begin._rhs) # array indexing is corrected in index macro
        step     = makeCStr(self._step)
        return "int {var} = {begin} + ({step})*(threadIdx.{idx} + blockIdx.{idx} * blockDim.{idx});\n".format(\
                var=indexVar,begin=begin,idx=self._threadIndex,step=step)
    def collapsedLoopIndexCStr(self,denominator):
        indexVar = self.loopVar()
        tid      = self._threadIndex
        assert not tid is None
        begin    = makeCStr(self._begin._rhs)
        size     = self.problemSizeCStr()
        step     = makeCStr(self._step)
        # int i<n> = begin<n> + step<n>*(i<denominator<n>> % size<n>)
        return "int {var} = {begin} + ({step})*({tid}{denom} % {size});\n".format(\
                var=indexVar,begin=begin,tid=tid,denom=denominator,size=size,step=step)
    def problemSizeCStr(self):
        if self._step == "1":
            return "(1 + (({end}) - ({begin})))".format(\
                begin=makeCStr(self._begin._rhs),end=makeCStr(self._end),step=makeCStr(self._step) )
        else:
            return "(1 + (({end}) - ({begin}))/({step}))".format(\
                begin=makeCStr(self._begin._rhs),end=makeCStr(self._end),step=makeCStr(self._step))
    def hipThreadBoundCStr(self) :
        indexVar = self.loopVar()
        begin    = makeCStr(self._begin._rhs)
        end      = makeCStr(self._end)
        step     = makeCStr(self._step)
        return "loop_cond({0},{1},{2})".format(indexVar, end, step)
    def loopVar(self,converter=makeCStr):
        return converter(self._begin._lhs)
    def cStr(self):
        indexVar    = self.loopVar()
        begin       = makeCStr(self._begin._rhs) # array indexing is corrected in index macro
        end         = makeCStr(self._end)
        step        = makeCStr(self._step)
        bodyContent = flattenBody(self._body) 
        if self._threadIndex == None:
            #print(self._body)
            return "for (int {0}={1}; {0} <= {2}; {0} += {3}) {{\n  {4}\n}}".format(indexVar, begin, end, step, bodyContent)
        else:
            return bodyContent

class IComputeConstruct():
    def identifiersInBody(self,converter=makeFStr):
        return []
    def arraysInBody(self,converter=makeFStr):
        return []
    def inoutArraysInBody(self,converter=makeFStr):
        return []
    def asyncNowait(): 
        """value != CLAUSE_NOT_FOUND means True"""
        return CLAUSE_NOT_FOUND
    def depend(self): 
        """ only OMP """
        #return { "in":[], "out":[], "inout":[], "inout":[], "mutexinoutset":[], "depobj":[] }
        return {}
    def deviceTypes(self): 
        return "*"
    def ifCondition(self): 
        """ OMP,ACC: accelerate only if condition is satisfied. Empty string means condition is satisfied. """
        return ""
    def selfCondition(self): 
        """ OMP,ACC: run on current CPU / device (and do not offload) """
        return ""
    def deviceptrs(self):
        return []
    def createAllocVars(self):
        return []
    def no_createVars(self):
        """ only ACC"""
        return []
    def presentVars(self):
        """ only ACC"""
        return []
    def deleteReleaseVars(self):
        return []
    def copyMapToFromVars(self):
        return []
    def copyinMapToVars(self):
        return []
    def copyoutMapFromVars(self):
        return []
    def attachVars(self):
        """ only ACC """
        return []
    def detachVars(self):
        """ only ACC """
        return []
    def presentByDefault(self):
        """ only ACC parallel """
        return True
    def gangTeamPrivateVars(self,converter=makeFStr): 
        return []
    def gangTeamFirstprivateVars(self,converter=makeFStr): 
        return []
    def gangTeamReductionVars(self,converter=makeFStr): 
        """ CUF,ACC: all scalars are private by default """ 
        return {}

class EmptyComputeConstruct(IComputeConstruct):
    """
    Fallback for failed full parse.
    Inteneded to reveal as much information as possible
    """
    def __init__(self,fSnippet):
        self._fSnippet = fSnippet
    def identifiersInBody(self,converter=makeFStr):
        valueType = lvalue | rvalue
        identifierNames = []
        for ident in valueType.scanString(self._fSnippet): # includes the identifiers of the function calls
            name      = converter(ident._value)
            nameLower = name.lower()
            definition,foundInIndex = indexertools.searchIndexForVariable(indexHints,nameLower)
            if (foundInIndex or\
               (not nameLower in KEYWORDS and\
               not nameLower in GPUFORT_CPP_ROUTINES)) and\
               not name in identifierNames: # using set destroys order
                identifierNames.append(name)
        return set(identifierNames)

class TTLoopKernel(TTNode,IComputeConstruct):
    def _assignFields(self):
        self._parentDirective, self._body = self.tokens
        if self._parentDirective is None:
            assert type(self._body) is TTDoLoop
            self._parentDirective = self._body.annotation()
        self._indexHints          = []
    def setIndexHints(self,indexHints):
        self._indexHints = indexHints
    def loopVars(self):
        identifierNames = []
        doLoops  = findAll(self._body,TTDoLoop)
        for loop in doLoops:
            identifierNames.append(loop.loopVar(makeFStr))
        return identifierNames
    def __searchValueInBody(self,searchFilter,indexHints,minRank=-1e20):
        identifierNames = [] 
        for valueType in findAllMatching(self._body,searchFilter): # includes the identifiers of the function calls
            name = makeFStr(valueType.name())
            nameLower = name.lower()
            definition,foundInIndex = indexertools.searchIndexForVariable(indexHints,nameLower)
            if (foundInIndex or\
                    (not nameLower in KEYWORDS and\
                    not nameLower in GPUFORT_CPP_ROUTINES)) and\
                    definition["rank"] >= -minRank and\
                    not name in identifierNames: # using set destroys order
                        identifierNames.append(name)
        return identifierNames
    def identifiersInBody(self,indexHints=[]):
        """
        :return: all identifiers of LValue and RValues in the body.
        """
        if len(indexHints):
            self._indexHints = indexHints
        return self.__searchValueInBody(lambda child: type(child) is IValue,
                self._indexHints)
        def arraysInBody(self,indexHints=[]):
            if len(indexHints):
                self._indexHints = indexHints
        def searchFilter(node):
            return type(child) is IValue and\
                    type(child._value) is TTFunctionCallOrTensorAccess 
        return self.__searchValueInBody(searchFilter,self._indexHints,1)
    def inoutArraysInBody(self,indexHints=[]):
        if len(indexHints):
            self._indexHints = indexHints
        def searchFilter(node):
            return type(child) is LValue and\
                    type(child._value) is TTFunctionCallOrTensorAccess 
        return self.__searchValueInBody(searchFilter,self._indexHints,1)
    def __localScalarsAndReductionCandidates(self,indexHints):
        """
        local variable      - scalar variable that is not read before the assignment (and is no derived type member)
        reductionCandidates - scalar variable that is written but not read anymore 

        NOTE: The loop variables need to be removed from this result when rendering the corresponding C kernel.
        NOTE: Implementatin assumes that loop condition variables are not written to in loop body. 
        NOTE: When rendering the kernel, it is best to exclude all variables for which an array declaration has been found,
        from the result list. TTCufKernelDo instances do not know of the type of the variables.
        """
        scalarsReadSoFar   = [] # per line, with name of lhs scalar removed from list
        initializedScalars = [] 

        # depth first search
        assignments = findAllMatching(self._body,
                lambda child: type(child) in 
                [TTAssignment,TTComplexAssignment,TTMatrixAssignment])
        for assignment in assignments:   
            # lhs scalars
            lvalue     = assignment._lhs._value
            lvalueName = makeFStr(lvalue._value)
            if type(lvalue) is TTIdentifier: # could still be a matrix
                definition,foundInIndex = indexertools.searchIndexForVariable(indexHints,lvalueName)
                if not foundInIndex or definition["rank"] == 0 and\
                        not lvalueName.lower() in scalarsReadSoFar:
                            initializedScalars.append(lvalueName) # read and initialized in 
            # rhs scalars
            rhsIdentifiers = findAll(assignment._rhs,TTIdentifier)
            for ttidentifier in rhsIdentifiers:
                nameLower = ttidentifier.fStr().lower()
                definition,foundInIndex = indexertools.searchIndexForVariable(indexHints,nameLower)
                if (not foundInIndex or definition["rank"] == 0) and\
                        nameLower != lvalueName.lower(): # do not include name of lhs if lhs appears in rhs
                            scalarsReadSoFar.append(nameLower)
        # initialized scalars that are not read (except in same statement) are likely reductions
        # initialized scalars that are read again in other statements are likely local variables
        reductionCandidates = [name for name in initializedScalars if name not in scalarsReadSoFar]
        localScalars        = [name for name in initializedScalars if name not in reductionCandidates] # contains loop variables
        loopVars = [var.lower() for var in self.loopVars()]
        for var in list(localScalars):
            if var.lower() in loopVars:
                localScalars.remove(var)
        return localScalars, reductionCandidates
    def localScalars(self,indexHints=[]):
        if len(indexHints):
            self._indexHints = indexHints
        localScalars,_ = self.__localScalarsAndReductionCandidates(self._indexHints)
        return localScalars 
    def reductionCandidates(self,indexHints=[]):
        if len(indexHints):
            self._indexHints = indexHints
        return self.__localScalarsAndReductionCandidates(self._indexHints)
    def problemSize(self):
        numOuterLoopsToMap = int(self._parentDirective.numCollapse())
        if LOOP_COLLAPSE_STRATEGY == "grid" or numOuterLoopsToMap == 1:
            numOuterLoopsToMap = min(3,numOuterLoopsToMap)
            result = ["-1"]*numOuterLoopsToMap
            doLoops = findAll(self._body,TTDoLoop)
            for i,loop in enumerate(doLoops):
                if i < numOuterLoopsToMap:
                    result[i] = loop.problemSizeCStr()
            return result
        else: # "collapse"
            result = ""
            doLoops = findAll(self._body,TTDoLoop)
            for loop in reversed(doLoops[0:numOuterLoopsToMap]):
                if len(result):
                    result += "*"
                result += loop.problemSizeCStr()
            if len(result):
                return [result]
            else:
                return ["-1"]
    def asyncNowait(): 
        """value != CLAUSE_NOT_FOUND means True"""
        return 
    def depend(self): 
        return self._parentDirective.depend()
    def deviceTypes(self): 
        return self._parentDirective.deviceTypes()
    def ifCondition(self): 
        return self._parentDirective.ifCondition()
    def selfCondition(self): 
        return self._parentDirective.selfCondition
    def deviceptrs(self):
        return self._parentDirective.deviceptrs()
    def createAllocVars(self):
        return self._parentDirective.createAllocVars()
    def no_createVars(self):
        return self._parentDirective.no_createVars()
    def presentVars(self):
        return self._parentDirective.presentVars()
    def deleteReleaseVars(self):
        return self._parentDirective.deleteReleaseVars()
    def copyMapToFromVars(self):
        return self._parentDirective.copyMapToFromVars()
    def copyinMapToVars(self):
        return self._parentDirective.copyinMapToVars()
    def copyoutMapFromVars(self):
        return self._parentDirective.copyoutMapFromVars()
    def attachVars(self):
        return self._parentDirective.attachVars()
    def detachVars(self):
        return self._parentDirective.detachVars()
    def presentByDefault(self):
        return self._parentDirective.detachVars()
    def gangTeamPrivateVars(self,converter=makeFStr): 
        return self._parentDirective.gangTeamPrivateVars(converter)
    def gangTeamFirstprivateVars(self,converter=makeFStr): 
        return self._parentDirective.gangTeamFirstprivateVars(converter)
    def gangTeamReductionVars(self,converter=makeFStr): 
        return self._parentDirective.gangTeamReductionVars(converter)
    def cStr(self):
        numOuterLoopsToMap = int(self._body.numCollapse())
        if LOOP_COLLAPSE_STRATEGY == "grid" and numOuterLoopsToMap <= 3:
            dim=numOuterLoopsToMap
        else: # "collapse" or numOuterLoopsToMap > 3
            dim=1
        tidx = "__gidx{dim}".format(dim=dim)
        # 1. unpack colon (":") expressions 
        for expr in findAll(self._body,TTStatement): 
            if type(expr._statement[0]) is TTAssignment:
                expr._statement[0] = expr._statement[0].convertToDoLoopNestIfNecessary()
        # 2. Identify reduction variables
        for expr in findAll(self._body,TTAssignment):
            for var in findAllMatching(expr,lambda x: isinstance(x,IValue)):
                if type(var._value) in [TTDerivedTypeMember,TTIdentifier]:
                    if var.name().lower() in self._reductionVars.keys():
                        var._reductionIndex = tidx
        reductionPreamble = ""
        for var,op in self._reductionVars.items():
            reductionPreamble += "reduce_op_{op}::init({var}[{tidx}]);\n".format(op=op,var=var,tidx=tidx)
        # 3. collapse and transform do-loops
        doLoops = findAll(self._body,TTDoLoop)
        numOuterLoopsToMap = int(self._launchInfo._numOuterLoopsToMap)
        if numOuterLoopsToMap is 1 or (LOOP_COLLAPSE_STRATEGY == "grid" and numOuterLoopsToMap <= 3):
            if numOuterLoopsToMap > 3:
                logging.getLogger("").warn("loop collapse strategy grid chosen with nested loops > 3")
            numOuterLoopsToMap = min(3,numOuterLoopsToMap)
            threadIndices = ["x","y","z"]
            for i in range(0,3-numOuterLoopsToMap):
                threadIndices.pop()
            indices    = ""
            conditions = []
            for loop in doLoops:
                if not len(threadIndices):
                    break
                loop.setHipThreadIndex(threadIndices.pop())
                indices   += loop.hipThreadIndexCStr()
                conditions.append(loop.hipThreadBoundCStr()) 
        else: # "collapse" or numOuterLoopsToMap > 3
            indices    = ""
            conditions = []
            denominatorFactors = []
            for loop in reversed(doLoops[0:numOuterLoopsToMap]):
                loop.setHipThreadIndex(tidx)
                # denominator1 = "" 
                # denominator2 = "/" + "(end1 - begin1 + 1)"
                # denominator3 = "/" + "(end1 - begin1 + 1)*(end1 - begin1 + 1)"
                if len(denominatorFactors):
                    indices += loop.collapsedLoopIndexCStr("/("+"*".join(denominatorFactors)+")")
                else:
                    indices += loop.collapsedLoopIndexCStr("")
                denominatorFactors.append(loop.problemSizeCStr())
                conditions.append(loop.hipThreadBoundCStr())
        cSnippet = "{0}{2}if ({1}) {{\n{3}}}".format(\
            indices,"&&".join(conditions),reductionPreamble,makeCStr(self._body))
        return postprocessCSnippet(cSnippet)

annotatedDoLoop.setParseAction(TTDoLoop)
loopKernel.setParseAction(TTLoopKernel)

# TODO parsing and translation is similar but analysis differs between the different kernel
# types. For example for CUF, the reduction vars must be detected by the parser (lhs scalars)
# while they are specified with ACC,OMP.
def parseLoopKernel(fortranSnippet,maxRecursions=30):
    """
    Return a csnippet equivalent to the original Fortran code.
    """
    global KEYWORDS 

    recursionsLeft=0
    def simplifyLoopKernelUntilItCanGetParsed(fortranSnippet,recursionsToGo):
        nonlocal recursionsLeft
        recursionsLeft = recursionsToGo
        try:
            return loopKernel.parseString(fortranSnippet)[0]
        except ParseBaseException as pbe:
            if recursionsToGo <= 0:
                raise pbe
            else:
                lineno = pbe.__getattr__("lineno")
                lines = fortranSnippet.split("\n")
                lines[lineno-1] = "! TODO could not parse: {}".format(lines[lineno-1])
                modifiedFortranSnippet = "\n".join(lines)
                #print(modifiedFortranSnippet)
                return simplifyLoopKernelUntilItCanGetParsed(modifiedFortranSnippet,recursionsToGo-1)
        except Exception as e:
            raise e        
   
    fortranSnippet = prepareFortranSnippet(fortranSnippet)
    try:
        computeConstruct = simplifyLoopKernelUntilItCanGetParsed(fortranSnippet,maxRecursions)
        if recursionsLeft < maxRecursions:
            body = "\n".join(fortranSnippet.split("\n")[1:])
        return computeConstruct
    except Exception as e:
        #raise e
        logger = logging.getLogger('') 
        logger.error("failed to convert kernel:\n{}".format(fortranSnippet))
        logger.error(str(e))
        return EmptyComputeConstruct(fsnippet)

def formatDirective(directiveLine,maxLineWidth):
    result   = ""
    line     = ""
    tokens   = directiveLine.split(" ")
    sentinel = tokens[0]
    for tk in tokens:
        if len(line+tk) > maxLineWidth-1:
            result += line + "&\n"
            line = sentinel+" "
        line += tk+" "
    result += line.rstrip() 
    return result
